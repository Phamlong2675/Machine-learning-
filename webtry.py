import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# ====== Placeholder: Import cÃ¡c hÃ m tá»« repo cá»§a báº¡n ======
# from model_utils import run_logistic_regression, run_gradient_descent, run_decision_function
# from preprocessing import preprocess_data, apply_scaler

# ====== Sidebar ======
st.sidebar.title("âš™ï¸ Options")

# Upload dá»¯ liá»‡u
st.sidebar.header("Upload Data (U)")
uploaded_file = st.sidebar.file_uploader("Choose a CSV/TXT file", type=["csv", "txt"])

# Chá»n mÃ´ hÃ¬nh
model_choice = st.sidebar.selectbox(
    "Choose model (M)",
    ["Logistic Regression (sklearn)", "Gradient Descent (custom)", "Decision Function g(s)", "SVM", "RandomForest"]
)

# Thiáº¿t láº­p tham sá»‘
st.sidebar.subheader("Parameters (T)")
iterations = st.sidebar.slider("Iterations", 100, 100000, step=1000, value=10000)
learning_rate = st.sidebar.number_input("Learning Rate", value=0.01, format="%.5f")
scaler_choice = st.sidebar.selectbox("Scaler", ["None", "Min-Max", "Standard"])

# Tiá»n xá»­ lÃ½ & Feature Engineering
st.sidebar.subheader("Features (F)")
normalize = st.sidebar.checkbox("Apply normalization")
feature_count = st.sidebar.radio("Number of features", [2, 6])

# NÃºt cháº¡y mÃ´ hÃ¬nh
if st.sidebar.button("ğŸš€ Run Model (R)"):
    st.session_state["run_model"] = True

# Xuáº¥t bÃ¡o cÃ¡o
if st.sidebar.button("ğŸ“¥ Download Report (D)"):
    # Placeholder: báº¡n tá»± implement export CSV/PDF
    st.success("Report generated!")

# ====== Main UI Tabs ======
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Training Results", "ğŸ“ˆ Comparison", "ğŸ’¬ Live Test"])

# ==== Tab 1: Training Results ====
with tab1:
    st.header("ğŸ“Š Training & Evaluation Results")

    if uploaded_file is not None and "run_model" in st.session_state:
        data = pd.read_csv(uploaded_file)  # hoáº·c txt parser
        st.write("Preview of uploaded data:", data.head())

        # Placeholder cháº¡y model
        # results = run_logistic_regression(data)  # vÃ­ dá»¥ gá»i hÃ m tá»« repo
        # precision, loss_curve, cm = results

        # Fake demo output
        precision = 0.87
        st.metric("Precision", f"{precision*100:.2f}%")

        st.subheader("Loss Curve")
        fig, ax = plt.subplots()
        ax.plot([0,1,2,3], [0.9,0.7,0.6,0.55])
        st.pyplot(fig)

        st.subheader("Confusion Matrix")
        st.table([[50, 10], [8, 60]])  # placeholder

# ==== Tab 2: Comparison ====
with tab2:
    st.header("ğŸ“ˆ Model Comparison")
    st.write("Compare Logistic Regression, Gradient Descent, Decision Function g(s), SVM, RandomForest")

    # Placeholder báº£ng káº¿t quáº£
    comp = pd.DataFrame({
        "Model": ["LogReg", "GD", "Decision g(s)", "SVM", "RF"],
        "Precision": [0.87, 0.82, 0.75, 0.89, 0.91]
    })
    st.table(comp)

    # Váº½ biá»ƒu Ä‘á»“
    fig2, ax2 = plt.subplots()
    comp.set_index("Model")["Precision"].plot(kind="bar", ax=ax2)
    st.pyplot(fig2)

# ==== Tab 3: Live Test ====
with tab3:
    st.header("ğŸ’¬ Test Your Sentence")
    user_input = st.text_input("Enter a sentence:", "")

    if st.button("Predict (S)"):
        if user_input.strip():
            # Placeholder gá»i hÃ m dá»± Ä‘oÃ¡n
            # sentiment = test_sentence(user_input)
            sentiment = "Positive ğŸ˜€" if "good" in user_input else "Negative ğŸ˜¡"
            st.success(f"Prediction: {sentiment}")

    # Benchmark vá»›i ChatGPT API (placeholder)
    if st.checkbox("Benchmark with ChatGPT/LLM"):
        st.info("This will call OpenAI API with your test sentence (implement yourself).")
