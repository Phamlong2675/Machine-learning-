{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "328347d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "985cf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english') \n",
    "    \n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tokenizer = nltk.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and \n",
    "            word not in string.punctuation):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "    return tweets_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a081abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    freqs = defaultdict(int)\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            freqs[(word, y[0])] += 1\n",
    "    return freqs\n",
    "\n",
    "# Load dữ liệu twitter_samples\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "train_x = all_positive_tweets[:4000] + all_negative_tweets[:4000]\n",
    "train_y = np.append(np.ones((4000,1)), np.zeros((4000,1)), axis=0)\n",
    "\n",
    "freqs = build_freqs(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd9facc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(tweet, freqs):\n",
    "    word_l = process_tweet(tweet)\n",
    "    x = np.zeros((1, 3)) \n",
    "    x[0,0] = 1 \n",
    "    for word in word_l:\n",
    "        x[0,1] += freqs.get((word,1.0), 0)\n",
    "        x[0,2] += freqs.get((word,0.0), 0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1610daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdb6cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_logistic(X, y, w, alpha, num_iters=100):\n",
    "    m = X.shape[0]\n",
    "    for i in range(num_iters):\n",
    "        z = np.dot(X, w)\n",
    "        h = sigmoid(z)\n",
    "        J = -1/m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h)))\n",
    "        w -= alpha/m * np.dot(X.T, (h-y))\n",
    "    return J, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c911b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic(X, w):\n",
    "    z = np.dot(X, w)\n",
    "    h = sigmoid(z)\n",
    "    return (h >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73ed777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :] = extract_features(train_x[i], freqs)\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de89be3",
   "metadata": {},
   "source": [
    "***Custom Logistic Regression:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fa320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "J, w = gradient_descent_logistic(X, Y, np.zeros((3, 1)), alpha=1e-9, num_iters=1500)\n",
    "y_pred_custom = predict_logistic(X, w)\n",
    "precision_custom = precision_score(Y, y_pred_custom)\n",
    "\n",
    "time_custom = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2198edc",
   "metadata": {},
   "source": [
    "***Sklearn Logistic Regression:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e30db0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, Y.ravel())\n",
    "\n",
    "y_pred_sklearn = clf.predict(X)\n",
    "precision_sklearn = precision_score(Y, y_pred_sklearn)\n",
    "\n",
    "time_sklearn = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bc1d5",
   "metadata": {},
   "source": [
    "***Comparison:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44135561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom: Precision = 0.9945, Time = 0.6402 seconds\n",
      "Sklearn: Precision = 0.9845, Time = 0.0165 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Custom: Precision = {precision_custom:.4f}, Time = {time_custom:.4f} seconds\")\n",
    "print(f\"Sklearn: Precision = {precision_sklearn:.4f}, Time = {time_sklearn:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
